{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 9)\n",
      "(400, 1)\n"
     ]
    }
   ],
   "source": [
    "# Boston_Dataset_Linear Regression\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "tf.random.set_seed(5)\n",
    "\n",
    "boston_train = np.loadtxt('boston_train.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "boston_test = np.loadtxt('boston_test.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "\n",
    "x_train = boston_train[:,:-1]\n",
    "y_train = boston_train[:,[-1]]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 초기화 : weight, bias\n",
    "W = tf.Variable(tf.random.normal([9, 1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis 예측 함수(방정식)  , H(x) = W * X + b\n",
    "def hypothesis(X):\n",
    "    return  tf.matmul(X,W) + b  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용함수 : (Hx - y)^2 의 평균\n",
    "def cost_func():\n",
    "    cost = tf.reduce_mean(tf.square((hypothesis(x_train) - y_train)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법\n",
    "# learning rate (학습율) 을 0.01로 설정하여  optimizer객체를 생성\n",
    "# optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Start Learning!!\n",
      "0000 cost: [ 3380.4307 ]  W:  [[-0.17030665]\n",
      " [-0.9402863 ]\n",
      " [-0.0296405 ]\n",
      " [-0.7325406 ]\n",
      " [ 1.3331523 ]\n",
      " [-0.60854805]\n",
      " [ 0.86406636]\n",
      " [-0.07899953]\n",
      " [ 2.4588697 ]]   b:  [0.23652864]\n",
      "1000 cost: [ 62.337715 ]  W:  [[-0.22907348]\n",
      " [ 0.15704152]\n",
      " [-0.2341578 ]\n",
      " [-0.55374366]\n",
      " [ 2.0969355 ]\n",
      " [-0.00413893]\n",
      " [-1.2355283 ]\n",
      " [-0.01346129]\n",
      " [ 1.1769997 ]]   b:  [0.04301885]\n",
      "2000 cost: [ 43.619267 ]  W:  [[-0.21055736]\n",
      " [ 0.11845101]\n",
      " [-0.26855505]\n",
      " [-0.02376875]\n",
      " [ 4.298945  ]\n",
      " [-0.02798385]\n",
      " [-1.5441726 ]\n",
      " [-0.0086548 ]\n",
      " [ 0.45516846]]   b:  [0.9228242]\n",
      "3000 cost: [ 36.123016 ]  W:  [[-1.8018964e-01]\n",
      " [ 7.6397851e-02]\n",
      " [-2.0762976e-01]\n",
      " [ 4.2566795e-02]\n",
      " [ 6.0564046e+00]\n",
      " [-4.8381828e-02]\n",
      " [-1.4871427e+00]\n",
      " [-6.0389736e-03]\n",
      " [-1.9743189e-01]]   b:  [1.7857456]\n",
      "4000 cost: [ 34.849686 ]  W:  [[-1.6464920e-01]\n",
      " [ 5.3313375e-02]\n",
      " [-1.6675106e-01]\n",
      " [-6.9249839e-01]\n",
      " [ 6.8752527e+00]\n",
      " [-5.4360438e-02]\n",
      " [-1.3683950e+00]\n",
      " [-4.4191191e-03]\n",
      " [-5.4338831e-01]]   b:  [2.5220294]\n",
      "5000 cost: [ 34.630127 ]  W:  [[-1.6099370e-01]\n",
      " [ 4.7722425e-02]\n",
      " [-1.5108059e-01]\n",
      " [-2.2039914e+00]\n",
      " [ 7.0557861e+00]\n",
      " [-5.3817473e-02]\n",
      " [-1.3494039e+00]\n",
      " [-3.8043666e-03]\n",
      " [-6.3172907e-01]]   b:  [3.3778586]\n",
      "6000 cost: [ 34.398834 ]  W:  [[-1.6050263e-01]\n",
      " [ 4.6896171e-02]\n",
      " [-1.4191699e-01]\n",
      " [-4.3419762e+00]\n",
      " [ 7.0563273e+00]\n",
      " [-5.1605731e-02]\n",
      " [-1.3767709e+00]\n",
      " [-3.3921469e-03]\n",
      " [-6.5746897e-01]]   b:  [4.7224183]\n",
      "7000 cost: [ 34.19313 ]  W:  [[-1.5976030e-01]\n",
      " [ 4.6424575e-02]\n",
      " [-1.3307659e-01]\n",
      " [-6.8762770e+00]\n",
      " [ 7.0083694e+00]\n",
      " [-4.8870672e-02]\n",
      " [-1.4195025e+00]\n",
      " [-2.4524881e-03]\n",
      " [-6.9176310e-01]]   b:  [6.7911386]\n",
      "8000 cost: [ 33.90936 ]  W:  [[-1.6001786e-01]\n",
      " [ 4.5638695e-02]\n",
      " [-1.2836382e-01]\n",
      " [-8.9464941e+00]\n",
      " [ 6.9347310e+00]\n",
      " [-4.7824744e-02]\n",
      " [-1.4623404e+00]\n",
      " [-2.4762584e-03]\n",
      " [-7.3003072e-01]]   b:  [8.931624]\n",
      "9000 cost: [ 33.736835 ]  W:  [[-1.5987095e-01]\n",
      " [ 4.5094520e-02]\n",
      " [-1.2532946e-01]\n",
      " [-1.0601686e+01]\n",
      " [ 6.8539953e+00]\n",
      " [-4.6900764e-02]\n",
      " [-1.5009960e+00]\n",
      " [-2.1186231e-03]\n",
      " [-7.6677102e-01]]   b:  [10.94539]\n",
      "10000 cost: [ 33.744633 ]  W:  [[-1.5909408e-01]\n",
      " [ 4.5220152e-02]\n",
      " [-1.2285680e-01]\n",
      " [-1.1958078e+01]\n",
      " [ 6.7748103e+00]\n",
      " [-4.5642413e-02]\n",
      " [-1.5349679e+00]\n",
      " [-1.1495309e-03]\n",
      " [-8.0022174e-01]]   b:  [12.783213]\n",
      "***** Learning Finished!!\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작\n",
    "print('***** Start Learning!!')\n",
    "for step in range(10001):\n",
    "    # cost를 minimize한다\n",
    "    optimizer.minimize(cost_func, var_list=[W,b])\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        print('%04d'%step, 'cost: [', cost_func().numpy(), ']  W: ', W.numpy(), '  b: ', b.numpy())\n",
    "        \n",
    "print('***** Learning Finished!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight = [[-1.5909408e-01]\n",
      " [ 4.5220152e-02]\n",
      " [-1.2285680e-01]\n",
      " [-1.1958078e+01]\n",
      " [ 6.7748103e+00]\n",
      " [-4.5642413e-02]\n",
      " [-1.5349679e+00]\n",
      " [-1.1495309e-03]\n",
      " [-8.0022174e-01]]\n",
      "Bias = [12.783213]\n"
     ]
    }
   ],
   "source": [
    "# 회귀 계수 출력\n",
    "print('Weight =', W.numpy())\n",
    "print('Bias =', b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "x_test = boston_test[:,:-1]\n",
    "y_test = boston_test[:,[-1]]\n",
    "\n",
    "preds = hypothesis(x_test).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.157873\n"
     ]
    }
   ],
   "source": [
    "# 정확도 측정(RMSE)\n",
    "def get_rmse(y_test,preds):\n",
    "    squared_error = 0\n",
    "    for k,_ in enumerate(y_test):\n",
    "        squared_error += (preds[k] - y_test[k])**2\n",
    "    mse = squared_error/len(y_test)    \n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse[0]  \n",
    "\n",
    "print('RMSE:', get_rmse(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
